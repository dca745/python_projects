{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark notebook ###\n",
    "\n",
    "This notebook will only work in a Jupyter session running on `mathmadslinux2p`.\n",
    "\n",
    "You can start your own Jupyter session on `mathmadslinux2p` and open this notebook in Chrome on the MADS Windows server by\n",
    "\n",
    "**Steps**\n",
    "\n",
    "1. Login to the MADS Windows server using https://mathportal.canterbury.ac.nz/.\n",
    "2. Download or copy this notebook to your home directory.\n",
    "3. Open powershell and run `ssh mathmadslinux2p`.\n",
    "4. Run `start_pyspark_notebook` or `/opt/anaconda3/bin/jupyter-notebook --ip 132.181.129.68 --port $((8000 + $((RANDOM % 999))))`.\n",
    "5. Copy / paste the url provided in the shell window into Chrome on the MADS Windows server.\n",
    "6. Open the notebook from the Jupyter root directory (which is your home directory).\n",
    "7. Run `start_spark()` to start a spark session in the notebook.\n",
    "8. Run `stop_spark()` before closing the notebook or kill your spark application by hand using the link in the Spark UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }table.dataframe td { white-space: nowrap !important; }table.dataframe thead th:first-child, table.dataframe tbody th { display: none; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell to import pyspark and to define start_spark() and stop_spark()\n",
    "\n",
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "import getpass\n",
    "import pandas\n",
    "import pyspark\n",
    "import random\n",
    "import re\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "# Functions used below\n",
    "\n",
    "def username():\n",
    "    \"\"\"Get username with any domain information removed.\n",
    "    \"\"\"\n",
    "\n",
    "    return re.sub('@.*', '', getpass.getuser())\n",
    "\n",
    "\n",
    "def dict_to_html(d):\n",
    "    \"\"\"Convert a Python dictionary into a two column table for display.\n",
    "    \"\"\"\n",
    "\n",
    "    html = []\n",
    "\n",
    "    html.append(f'<table width=\"100%\" style=\"width:100%; font-family: monospace;\">')\n",
    "    for k, v in d.items():\n",
    "        html.append(f'<tr><td style=\"text-align:left;\">{k}</td><td>{v}</td></tr>')\n",
    "    html.append(f'</table>')\n",
    "\n",
    "    return ''.join(html)\n",
    "\n",
    "\n",
    "def show_as_html(df, n=20):\n",
    "    \"\"\"Leverage existing pandas jupyter integration to show a spark dataframe as html.\n",
    "    \n",
    "    Args:\n",
    "        n (int): number of rows to show (default: 20)\n",
    "    \"\"\"\n",
    "\n",
    "    display(df.limit(n).toPandas())\n",
    "\n",
    "    \n",
    "def display_spark():\n",
    "    \"\"\"Display the status of the active Spark session if one is currently running.\n",
    "    \"\"\"\n",
    "    \n",
    "    if 'spark' in globals() and 'sc' in globals():\n",
    "\n",
    "        name = sc.getConf().get(\"spark.app.name\")\n",
    "        \n",
    "        html = [\n",
    "            f'<p><b>Spark</b></p>',\n",
    "            f'<p>The spark session is <b><span style=\"color:green\">active</span></b>, look for <code>{name}</code> under the running applications section in the Spark UI.</p>',\n",
    "            f'<ul>',\n",
    "            f'<li><a href=\"http://mathmadslinux2p.canterbury.ac.nz:8080/\" target=\"_blank\">Spark UI</a></li>',\n",
    "            f'<li><a href=\"{sc.uiWebUrl}\" target=\"_blank\">Spark Application UI</a></li>',\n",
    "            f'</ul>',\n",
    "            f'<p><b>Config</b></p>',\n",
    "            dict_to_html(dict(sc.getConf().getAll())),\n",
    "            f'<p><b>Notes</b></p>',\n",
    "            f'<ul>',\n",
    "            f'<li>The spark session <code>spark</code> and spark context <code>sc</code> global variables have been defined by <code>start_spark()</code>.</li>',\n",
    "            f'<li>Please run <code>stop_spark()</code> before closing the notebook or restarting the kernel or kill <code>{name}</code> by hand using the link in the Spark UI.</li>',\n",
    "            f'</ul>',\n",
    "        ]\n",
    "        display(HTML(''.join(html)))\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        html = [\n",
    "            f'<p><b>Spark</b></p>',\n",
    "            f'<p>The spark session is <b><span style=\"color:red\">stopped</span></b>, confirm that <code>{username() + \" (jupyter)\"}</code> is under the completed applications section in the Spark UI.</p>',\n",
    "            f'<ul>',\n",
    "            f'<li><a href=\"http://mathmadslinux2p.canterbury.ac.nz:8080/\" target=\"_blank\">Spark UI</a></li>',\n",
    "            f'</ul>',\n",
    "        ]\n",
    "        display(HTML(''.join(html)))\n",
    "\n",
    "\n",
    "# Functions to start and stop spark\n",
    "\n",
    "def start_spark(executor_instances=2, executor_cores=1, worker_memory=1, master_memory=1):\n",
    "    \"\"\"Start a new Spark session and define globals for SparkSession (spark) and SparkContext (sc).\n",
    "    \n",
    "    Args:\n",
    "        executor_instances (int): number of executors (default: 2)\n",
    "        executor_cores (int): number of cores per executor (default: 1)\n",
    "        worker_memory (float): worker memory (default: 1)\n",
    "        master_memory (float): master memory (default: 1)\n",
    "    \"\"\"\n",
    "\n",
    "    global spark\n",
    "    global sc\n",
    "\n",
    "    user = username()\n",
    "    \n",
    "    cores = executor_instances * executor_cores\n",
    "    partitions = cores * 4\n",
    "    port = 4000 + random.randint(1, 999)\n",
    "\n",
    "    spark = (\n",
    "        SparkSession.builder\n",
    "        .master(\"spark://masternode2:7077\")\n",
    "        .config(\"spark.driver.extraJavaOptions\", f\"-Dderby.system.home=/tmp/{user}/spark/\")\n",
    "        .config(\"spark.dynamicAllocation.enabled\", \"false\")\n",
    "        .config(\"spark.executor.instances\", str(executor_instances))\n",
    "        .config(\"spark.executor.cores\", str(executor_cores))\n",
    "        .config(\"spark.cores.max\", str(cores))\n",
    "        .config(\"spark.executor.memory\", f\"{worker_memory}g\")\n",
    "        .config(\"spark.driver.memory\", f\"{master_memory}g\")\n",
    "        .config(\"spark.driver.maxResultSize\", \"0\")\n",
    "        .config(\"spark.sql.shuffle.partitions\", str(partitions))\n",
    "        .config(\"spark.ui.port\", str(port))\n",
    "        .appName(user + \" (jupyter)\")\n",
    "        .getOrCreate()\n",
    "    )\n",
    "    sc = SparkContext.getOrCreate()\n",
    "    \n",
    "    display_spark()\n",
    "\n",
    "    \n",
    "def stop_spark():\n",
    "    \"\"\"Stop the active Spark session and delete globals for SparkSession (spark) and SparkContext (sc).\n",
    "    \"\"\"\n",
    "\n",
    "    global spark\n",
    "    global sc\n",
    "\n",
    "    if 'spark' in globals() and 'sc' in globals():\n",
    "\n",
    "        spark.stop()\n",
    "\n",
    "        del spark\n",
    "        del sc\n",
    "\n",
    "    display_spark()\n",
    "\n",
    "\n",
    "# Make css changes to improve spark output readability\n",
    "\n",
    "html = [\n",
    "    '<style>',\n",
    "    'pre { white-space: pre !important; }',\n",
    "    'table.dataframe td { white-space: nowrap !important; }',\n",
    "    'table.dataframe thead th:first-child, table.dataframe tbody th { display: none; }',\n",
    "    '</style>',\n",
    "]\n",
    "display(HTML(''.join(html)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example notebook ###\n",
    "\n",
    "The code below provides a template for how you would use a notebook to start spark, run some code, and then stop spark.\n",
    "\n",
    "**Steps**\n",
    "\n",
    "- Run `start_spark()` to start a spark session in the notebook (only change the default resources when advised to do so for an exercise or assignment)\n",
    "- Write and run code interactively, creating additional cells as needed.\n",
    "- Run `stop_spark()` before closing the notebook or kill your spark application by hand using the link in the [Spark UI](http://mathmadslinux2p.canterbury.ac.nz:8080/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><b>Spark</b></p><p>The spark session is <b><span style=\"color:green\">active</span></b>, look for <code>dca129 (jupyter)</code> under the running applications section in the Spark UI.</p><ul><li><a href=\"http://mathmadslinux2p.canterbury.ac.nz:8080/\" target=\"_blank\">Spark UI</a></li><li><a href=\"http://mathmadslinux2p.canterbury.ac.nz:4771\" target=\"_blank\">Spark Application UI</a></li></ul><p><b>Config</b></p><table width=\"100%\" style=\"width:100%; font-family: monospace;\"><tr><td style=\"text-align:left;\">spark.sql.shuffle.partitions</td><td>64</td></tr><tr><td style=\"text-align:left;\">spark.dynamicAllocation.enabled</td><td>false</td></tr><tr><td style=\"text-align:left;\">spark.executor.instances</td><td>4</td></tr><tr><td style=\"text-align:left;\">spark.driver.port</td><td>32829</td></tr><tr><td style=\"text-align:left;\">spark.master</td><td>spark://masternode2:7077</td></tr><tr><td style=\"text-align:left;\">spark.cores.max</td><td>16</td></tr><tr><td style=\"text-align:left;\">spark.executor.id</td><td>driver</td></tr><tr><td style=\"text-align:left;\">spark.sql.warehouse.dir</td><td>file:/users/home/dca129/Assignment1/spark-warehouse</td></tr><tr><td style=\"text-align:left;\">spark.driver.host</td><td>mathmadslinux2p.canterbury.ac.nz</td></tr><tr><td style=\"text-align:left;\">spark.executor.cores</td><td>4</td></tr><tr><td style=\"text-align:left;\">spark.app.id</td><td>app-20240914193118-0948</td></tr><tr><td style=\"text-align:left;\">spark.executor.memory</td><td>16g</td></tr><tr><td style=\"text-align:left;\">spark.ui.port</td><td>4771</td></tr><tr><td style=\"text-align:left;\">spark.driver.extraJavaOptions</td><td>-Dderby.system.home=/tmp/dca129/spark/</td></tr><tr><td style=\"text-align:left;\">spark.app.name</td><td>dca129 (jupyter)</td></tr><tr><td style=\"text-align:left;\">spark.rdd.compress</td><td>True</td></tr><tr><td style=\"text-align:left;\">spark.driver.memory</td><td>2g</td></tr><tr><td style=\"text-align:left;\">spark.driver.maxResultSize</td><td>0</td></tr><tr><td style=\"text-align:left;\">spark.serializer.objectStreamReset</td><td>100</td></tr><tr><td style=\"text-align:left;\">spark.submit.pyFiles</td><td></td></tr><tr><td style=\"text-align:left;\">spark.submit.deployMode</td><td>client</td></tr><tr><td style=\"text-align:left;\">spark.ui.showConsoleProgress</td><td>true</td></tr><tr><td style=\"text-align:left;\">spark.app.startTime</td><td>1726299077028</td></tr></table><p><b>Notes</b></p><ul><li>The spark session <code>spark</code> and spark context <code>sc</code> global variables have been defined by <code>start_spark()</code>.</li><li>Please run <code>stop_spark()</code> before closing the notebook or restarting the kernel or kill <code>dca129 (jupyter)</code> by hand using the link in the Spark UI.</li></ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell to start a spark session in this notebook\n",
    "\n",
    "start_spark(executor_instances=4, executor_cores=4, worker_memory=16, master_memory=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your imports here or insert cells below\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import to_date,substring,length\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create schema for daily\n",
    "\n",
    "daily_schema = StructType([\n",
    "    StructField(\"ID\",StringType(),True),\n",
    "    #StructField(\"Date\",DateType(),True),\n",
    "    StructField(\"Date\",StringType(),True),\n",
    "    StructField(\"Element\",StringType(),True),\n",
    "    StructField(\"Value\",FloatType(),True),\n",
    "    StructField(\"Measurement Flag\",StringType(),True),\n",
    "    StructField(\"Quality Flag\",StringType(),True),\n",
    "    StructField(\"Source Flag\",StringType(),True),\n",
    "    StructField(\"Observation Time\",StringType(),True),\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1.a\n",
    "# Load MetaData\n",
    "# Loading 'Stations', 'States', 'Countries', 'Inventory' datasets \n",
    "\n",
    "stations_file_path = \"hdfs:///data/ghcnd/ghcnd-stations.txt\"\n",
    "\n",
    "states_file_path = \"hdfs:///data/ghcnd/ghcnd-states.txt\"\n",
    "\n",
    "countries_file_path = \"hdfs:///data/ghcnd/ghcnd-countries.txt\"\n",
    "\n",
    "inventory_file_path = \"hdfs:///data/ghcnd/ghcnd-inventory.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>STATE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>GSN_FLAG</th>\n",
       "      <th>HCN_CRN_FLAG</th>\n",
       "      <th>WMO_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACW00011604</td>\n",
       "      <td>17.1167</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>10.1</td>\n",
       "      <td></td>\n",
       "      <td>ST JOHNS COOLIDGE FLD</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACW00011647</td>\n",
       "      <td>17.1333</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>19.2</td>\n",
       "      <td></td>\n",
       "      <td>ST JOHNS</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>25.3330</td>\n",
       "      <td>55.5170</td>\n",
       "      <td>34.0</td>\n",
       "      <td></td>\n",
       "      <td>SHARJAH INTER. AIRP</td>\n",
       "      <td>GSN</td>\n",
       "      <td></td>\n",
       "      <td>41196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEM00041194</td>\n",
       "      <td>25.2550</td>\n",
       "      <td>55.3640</td>\n",
       "      <td>10.4</td>\n",
       "      <td></td>\n",
       "      <td>DUBAI INTL</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>41194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AEM00041217</td>\n",
       "      <td>24.4330</td>\n",
       "      <td>54.6510</td>\n",
       "      <td>26.8</td>\n",
       "      <td></td>\n",
       "      <td>ABU DHABI INTL</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>41217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AEM00041218</td>\n",
       "      <td>24.2620</td>\n",
       "      <td>55.6090</td>\n",
       "      <td>264.9</td>\n",
       "      <td></td>\n",
       "      <td>AL AIN INTL</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>41218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AF000040930</td>\n",
       "      <td>35.3170</td>\n",
       "      <td>69.0170</td>\n",
       "      <td>3366.0</td>\n",
       "      <td></td>\n",
       "      <td>NORTH-SALANG</td>\n",
       "      <td>GSN</td>\n",
       "      <td></td>\n",
       "      <td>40930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AFM00040938</td>\n",
       "      <td>34.2100</td>\n",
       "      <td>62.2280</td>\n",
       "      <td>977.2</td>\n",
       "      <td></td>\n",
       "      <td>HERAT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>40938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AFM00040948</td>\n",
       "      <td>34.5660</td>\n",
       "      <td>69.2120</td>\n",
       "      <td>1791.3</td>\n",
       "      <td></td>\n",
       "      <td>KABUL INTL</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>40948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AFM00040990</td>\n",
       "      <td>31.5000</td>\n",
       "      <td>65.8500</td>\n",
       "      <td>1010.0</td>\n",
       "      <td></td>\n",
       "      <td>KANDAHAR AIRPORT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>40990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AG000060390</td>\n",
       "      <td>36.7167</td>\n",
       "      <td>3.2500</td>\n",
       "      <td>24.0</td>\n",
       "      <td></td>\n",
       "      <td>ALGER-DAR EL BEIDA</td>\n",
       "      <td>GSN</td>\n",
       "      <td></td>\n",
       "      <td>60390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AG000060590</td>\n",
       "      <td>30.5667</td>\n",
       "      <td>2.8667</td>\n",
       "      <td>397.0</td>\n",
       "      <td></td>\n",
       "      <td>EL-GOLEA</td>\n",
       "      <td>GSN</td>\n",
       "      <td></td>\n",
       "      <td>60590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AG000060611</td>\n",
       "      <td>28.0500</td>\n",
       "      <td>9.6331</td>\n",
       "      <td>561.0</td>\n",
       "      <td></td>\n",
       "      <td>IN-AMENAS</td>\n",
       "      <td>GSN</td>\n",
       "      <td></td>\n",
       "      <td>60611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AG000060680</td>\n",
       "      <td>22.8000</td>\n",
       "      <td>5.4331</td>\n",
       "      <td>1362.0</td>\n",
       "      <td></td>\n",
       "      <td>TAMANRASSET</td>\n",
       "      <td>GSN</td>\n",
       "      <td></td>\n",
       "      <td>60680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AGE00135039</td>\n",
       "      <td>35.7297</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>50.0</td>\n",
       "      <td></td>\n",
       "      <td>ORAN-HOPITAL MILITAIRE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AGE00147704</td>\n",
       "      <td>36.9700</td>\n",
       "      <td>7.7900</td>\n",
       "      <td>161.0</td>\n",
       "      <td></td>\n",
       "      <td>ANNABA-CAP DE GARDE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AGE00147705</td>\n",
       "      <td>36.7800</td>\n",
       "      <td>3.0700</td>\n",
       "      <td>59.0</td>\n",
       "      <td></td>\n",
       "      <td>ALGIERS-VILLE/UNIVERSITE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AGE00147706</td>\n",
       "      <td>36.8000</td>\n",
       "      <td>3.0300</td>\n",
       "      <td>344.0</td>\n",
       "      <td></td>\n",
       "      <td>ALGIERS-BOUZAREAH</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AGE00147707</td>\n",
       "      <td>36.8000</td>\n",
       "      <td>3.0400</td>\n",
       "      <td>38.0</td>\n",
       "      <td></td>\n",
       "      <td>ALGIERS-CAP CAXINE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AGE00147708</td>\n",
       "      <td>36.7200</td>\n",
       "      <td>4.0500</td>\n",
       "      <td>222.0</td>\n",
       "      <td></td>\n",
       "      <td>TIZI OUZOU</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>60395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  LATITUDE  LONGITUDE  ELEVATION STATE  \\\n",
       "0   ACW00011604   17.1167   -61.7833       10.1         \n",
       "1   ACW00011647   17.1333   -61.7833       19.2         \n",
       "2   AE000041196   25.3330    55.5170       34.0         \n",
       "3   AEM00041194   25.2550    55.3640       10.4         \n",
       "4   AEM00041217   24.4330    54.6510       26.8         \n",
       "5   AEM00041218   24.2620    55.6090      264.9         \n",
       "6   AF000040930   35.3170    69.0170     3366.0         \n",
       "7   AFM00040938   34.2100    62.2280      977.2         \n",
       "8   AFM00040948   34.5660    69.2120     1791.3         \n",
       "9   AFM00040990   31.5000    65.8500     1010.0         \n",
       "10  AG000060390   36.7167     3.2500       24.0         \n",
       "11  AG000060590   30.5667     2.8667      397.0         \n",
       "12  AG000060611   28.0500     9.6331      561.0         \n",
       "13  AG000060680   22.8000     5.4331     1362.0         \n",
       "14  AGE00135039   35.7297     0.6500       50.0         \n",
       "15  AGE00147704   36.9700     7.7900      161.0         \n",
       "16  AGE00147705   36.7800     3.0700       59.0         \n",
       "17  AGE00147706   36.8000     3.0300      344.0         \n",
       "18  AGE00147707   36.8000     3.0400       38.0         \n",
       "19  AGE00147708   36.7200     4.0500      222.0         \n",
       "\n",
       "                              NAME GSN_FLAG HCN_CRN_FLAG WMO_ID  \n",
       "0   ST JOHNS COOLIDGE FLD                                        \n",
       "1   ST JOHNS                                                     \n",
       "2   SHARJAH INTER. AIRP                 GSN               41196  \n",
       "3   DUBAI INTL                                            41194  \n",
       "4   ABU DHABI INTL                                        41217  \n",
       "5   AL AIN INTL                                           41218  \n",
       "6   NORTH-SALANG                        GSN               40930  \n",
       "7   HERAT                                                 40938  \n",
       "8   KABUL INTL                                            40948  \n",
       "9   KANDAHAR AIRPORT                                      40990  \n",
       "10  ALGER-DAR EL BEIDA                  GSN               60390  \n",
       "11  EL-GOLEA                            GSN               60590  \n",
       "12  IN-AMENAS                           GSN               60611  \n",
       "13  TAMANRASSET                         GSN               60680  \n",
       "14  ORAN-HOPITAL MILITAIRE                                       \n",
       "15  ANNABA-CAP DE GARDE                                          \n",
       "16  ALGIERS-VILLE/UNIVERSITE                                     \n",
       "17  ALGIERS-BOUZAREAH                                            \n",
       "18  ALGIERS-CAP CAXINE                                           \n",
       "19  TIZI OUZOU                                            60395  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load ghcnd-stations.txt into spark\n",
    "raw_stations = spark.read.text(stations_file_path)\n",
    "\n",
    "# Show the content of the DataFrame\n",
    "#raw_stations.show(truncate=False)\n",
    "\n",
    "#parsing using substring pyspark.sql function\n",
    "df_stations = raw_stations.select(\n",
    "    substring(\"value\", 1, 11).alias(\"ID\"),\n",
    "    substring(\"value\", 13, 8).cast(DoubleType()).alias(\"LATITUDE\"),\n",
    "    substring(\"value\", 22, 9).cast(DoubleType()).alias(\"LONGITUDE\"),\n",
    "    substring(\"value\", 32, 6).cast(DoubleType()).alias(\"ELEVATION\"),\n",
    "    substring(\"value\", 39, 2).alias(\"STATE\"),\n",
    "    substring(\"value\", 42, 30).alias(\"NAME\"),\n",
    "    substring(\"value\", 73, 3).alias(\"GSN_FLAG\"),\n",
    "    substring(\"value\", 77, 3).alias(\"HCN_CRN_FLAG\"),\n",
    "    substring(\"value\", 81, 5).alias(\"WMO_ID\"),\n",
    ")\n",
    "\n",
    "show_as_html(df_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+\n",
      "|value                                             |\n",
      "+--------------------------------------------------+\n",
      "|AB ALBERTA                                        |\n",
      "|AK ALASKA                                         |\n",
      "|AL ALABAMA                                        |\n",
      "|AR ARKANSAS                                       |\n",
      "|AS AMERICAN SAMOA                                 |\n",
      "|AZ ARIZONA                                        |\n",
      "|BC BRITISH COLUMBIA                               |\n",
      "|CA CALIFORNIA                                     |\n",
      "|CO COLORADO                                       |\n",
      "|CT CONNECTICUT                                    |\n",
      "|DC DISTRICT OF COLUMBIA                           |\n",
      "|DE DELAWARE                                       |\n",
      "|FL FLORIDA                                        |\n",
      "|FM MICRONESIA                                     |\n",
      "|GA GEORGIA                                        |\n",
      "|GU GUAM                                           |\n",
      "|HI HAWAII                                         |\n",
      "|IA IOWA                                           |\n",
      "|ID IDAHO                                          |\n",
      "|IL ILLINOIS                                       |\n",
      "+--------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODE</th>\n",
       "      <th>NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AB</td>\n",
       "      <td>ALBERTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>ALABAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR</td>\n",
       "      <td>ARKANSAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AS</td>\n",
       "      <td>AMERICAN SAMOA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AZ</td>\n",
       "      <td>ARIZONA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BC</td>\n",
       "      <td>BRITISH COLUMBIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CO</td>\n",
       "      <td>COLORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CT</td>\n",
       "      <td>CONNECTICUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DC</td>\n",
       "      <td>DISTRICT OF COLUMBIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DE</td>\n",
       "      <td>DELAWARE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FL</td>\n",
       "      <td>FLORIDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FM</td>\n",
       "      <td>MICRONESIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GA</td>\n",
       "      <td>GEORGIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GU</td>\n",
       "      <td>GUAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HI</td>\n",
       "      <td>HAWAII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>IA</td>\n",
       "      <td>IOWA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ID</td>\n",
       "      <td>IDAHO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>IL</td>\n",
       "      <td>ILLINOIS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CODE                                            NAME\n",
       "0    AB                                         ALBERTA\n",
       "1    AK                                          ALASKA\n",
       "2    AL  ALABAMA                                       \n",
       "3    AR                                        ARKANSAS\n",
       "4    AS                                  AMERICAN SAMOA\n",
       "5    AZ                                         ARIZONA\n",
       "6    BC                                BRITISH COLUMBIA\n",
       "7    CA                                      CALIFORNIA\n",
       "8    CO                                        COLORADO\n",
       "9    CT                                     CONNECTICUT\n",
       "10   DC                            DISTRICT OF COLUMBIA\n",
       "11   DE                                        DELAWARE\n",
       "12   FL                                         FLORIDA\n",
       "13   FM                                      MICRONESIA\n",
       "14   GA                                         GEORGIA\n",
       "15   GU                                            GUAM\n",
       "16   HI                                          HAWAII\n",
       "17   IA                                            IOWA\n",
       "18   ID                                           IDAHO\n",
       "19   IL                                        ILLINOIS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load ghcnd-states.txt into spark\n",
    "raw_states = spark.read.text(states_file_path)\n",
    "\n",
    "# Show the content of the DataFrame\n",
    "raw_states.show(truncate=False)\n",
    "\n",
    "#parsing using substring pyspark.sql function\n",
    "df_states = raw_states.select(\n",
    "    substring(\"value\", 1, 2).alias(\"CODE\"),\n",
    "    substring(\"value\", 4, 46).alias(\"NAME\"),\n",
    ")\n",
    "\n",
    "show_as_html(df_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+\n",
      "|value                             |\n",
      "+----------------------------------+\n",
      "|AC Antigua and Barbuda            |\n",
      "|AE United Arab Emirates           |\n",
      "|AF Afghanistan                    |\n",
      "|AG Algeria                        |\n",
      "|AJ Azerbaijan                     |\n",
      "|AL Albania                        |\n",
      "|AM Armenia                        |\n",
      "|AO Angola                         |\n",
      "|AQ American Samoa [United States] |\n",
      "|AR Argentina                      |\n",
      "|AS Australia                      |\n",
      "|AU Austria                        |\n",
      "|AY Antarctica                     |\n",
      "|BA Bahrain                        |\n",
      "|BB Barbados                       |\n",
      "|BC Botswana                       |\n",
      "|BD Bermuda [United Kingdom]       |\n",
      "|BE Belgium                        |\n",
      "|BF Bahamas, The                   |\n",
      "|BG Bangladesh                     |\n",
      "+----------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODE</th>\n",
       "      <th>NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AC</td>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AE</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AG</td>\n",
       "      <td>Algeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AJ</td>\n",
       "      <td>Azerbaijan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AL</td>\n",
       "      <td>Albania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AM</td>\n",
       "      <td>Armenia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AO</td>\n",
       "      <td>Angola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AQ</td>\n",
       "      <td>American Samoa [United States]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AR</td>\n",
       "      <td>Argentina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AS</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AU</td>\n",
       "      <td>Austria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AY</td>\n",
       "      <td>Antarctica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BA</td>\n",
       "      <td>Bahrain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BB</td>\n",
       "      <td>Barbados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BC</td>\n",
       "      <td>Botswana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BD</td>\n",
       "      <td>Bermuda [United Kingdom]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BE</td>\n",
       "      <td>Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BF</td>\n",
       "      <td>Bahamas, The</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BG</td>\n",
       "      <td>Bangladesh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CODE                             NAME\n",
       "0    AC             Antigua and Barbuda \n",
       "1    AE            United Arab Emirates \n",
       "2    AF                      Afghanistan\n",
       "3    AG                         Algeria \n",
       "4    AJ                      Azerbaijan \n",
       "5    AL                          Albania\n",
       "6    AM                         Armenia \n",
       "7    AO                          Angola \n",
       "8    AQ  American Samoa [United States] \n",
       "9    AR                       Argentina \n",
       "10   AS                       Australia \n",
       "11   AU                         Austria \n",
       "12   AY                      Antarctica \n",
       "13   BA                         Bahrain \n",
       "14   BB                        Barbados \n",
       "15   BC                        Botswana \n",
       "16   BD        Bermuda [United Kingdom] \n",
       "17   BE                         Belgium \n",
       "18   BF                    Bahamas, The \n",
       "19   BG                       Bangladesh"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load ghcnd-countries.txt into spark\n",
    "raw_countries = spark.read.text(countries_file_path)\n",
    "\n",
    "# Show the content of the DataFrame\n",
    "raw_countries.show(truncate=False)\n",
    "\n",
    "#parsing using substring pyspark.sql function\n",
    "df_countries = raw_countries.select(\n",
    "    substring(\"value\", 1, 2).alias(\"CODE\"),\n",
    "    substring(\"value\", 4, 60).alias(\"NAME\"),\n",
    ")\n",
    "\n",
    "show_as_html(df_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+\n",
      "|value                                        |\n",
      "+---------------------------------------------+\n",
      "|ACW00011604  17.1167  -61.7833 TMAX 1949 1949|\n",
      "|ACW00011604  17.1167  -61.7833 TMIN 1949 1949|\n",
      "|ACW00011604  17.1167  -61.7833 PRCP 1949 1949|\n",
      "|ACW00011604  17.1167  -61.7833 SNOW 1949 1949|\n",
      "|ACW00011604  17.1167  -61.7833 SNWD 1949 1949|\n",
      "|ACW00011604  17.1167  -61.7833 PGTM 1949 1949|\n",
      "|ACW00011604  17.1167  -61.7833 WDFG 1949 1949|\n",
      "|ACW00011604  17.1167  -61.7833 WSFG 1949 1949|\n",
      "|ACW00011604  17.1167  -61.7833 WT03 1949 1949|\n",
      "|ACW00011604  17.1167  -61.7833 WT08 1949 1949|\n",
      "|ACW00011604  17.1167  -61.7833 WT16 1949 1949|\n",
      "|ACW00011647  17.1333  -61.7833 TMAX 1961 1961|\n",
      "|ACW00011647  17.1333  -61.7833 TMIN 1961 1961|\n",
      "|ACW00011647  17.1333  -61.7833 PRCP 1957 1970|\n",
      "|ACW00011647  17.1333  -61.7833 SNOW 1957 1970|\n",
      "|ACW00011647  17.1333  -61.7833 SNWD 1957 1970|\n",
      "|ACW00011647  17.1333  -61.7833 WT03 1961 1961|\n",
      "|ACW00011647  17.1333  -61.7833 WT16 1961 1966|\n",
      "|AE000041196  25.3330   55.5170 TMAX 1944 2024|\n",
      "|AE000041196  25.3330   55.5170 TMIN 1944 2024|\n",
      "+---------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEMENT</th>\n",
       "      <th>FIRSTYEAR</th>\n",
       "      <th>LASTYEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACW00011604</td>\n",
       "      <td>17.1167</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>1949</td>\n",
       "      <td>1949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACW00011604</td>\n",
       "      <td>17.1167</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>1949</td>\n",
       "      <td>1949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACW00011604</td>\n",
       "      <td>17.1167</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>1949</td>\n",
       "      <td>1949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACW00011604</td>\n",
       "      <td>17.1167</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>1949</td>\n",
       "      <td>1949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACW00011604</td>\n",
       "      <td>17.1167</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>SNWD</td>\n",
       "      <td>1949</td>\n",
       "      <td>1949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ACW00011604</td>\n",
       "      <td>17.1167</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>PGTM</td>\n",
       "      <td>1949</td>\n",
       "      <td>1949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACW00011604</td>\n",
       "      <td>17.1167</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>WDFG</td>\n",
       "      <td>1949</td>\n",
       "      <td>1949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACW00011604</td>\n",
       "      <td>17.1167</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>WSFG</td>\n",
       "      <td>1949</td>\n",
       "      <td>1949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ACW00011604</td>\n",
       "      <td>17.1167</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>WT03</td>\n",
       "      <td>1949</td>\n",
       "      <td>1949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ACW00011604</td>\n",
       "      <td>17.1167</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>WT08</td>\n",
       "      <td>1949</td>\n",
       "      <td>1949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACW00011604</td>\n",
       "      <td>17.1167</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>WT16</td>\n",
       "      <td>1949</td>\n",
       "      <td>1949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ACW00011647</td>\n",
       "      <td>17.1333</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ACW00011647</td>\n",
       "      <td>17.1333</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ACW00011647</td>\n",
       "      <td>17.1333</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>1957</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ACW00011647</td>\n",
       "      <td>17.1333</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>1957</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ACW00011647</td>\n",
       "      <td>17.1333</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>SNWD</td>\n",
       "      <td>1957</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ACW00011647</td>\n",
       "      <td>17.1333</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>WT03</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ACW00011647</td>\n",
       "      <td>17.1333</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>WT16</td>\n",
       "      <td>1961</td>\n",
       "      <td>1966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>25.3330</td>\n",
       "      <td>55.5170</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>1944</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>25.3330</td>\n",
       "      <td>55.5170</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>1944</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  LATITUDE  LONGITUDE ELEMENT  FIRSTYEAR  LASTYEAR\n",
       "0   ACW00011604   17.1167   -61.7833    TMAX       1949      1949\n",
       "1   ACW00011604   17.1167   -61.7833    TMIN       1949      1949\n",
       "2   ACW00011604   17.1167   -61.7833    PRCP       1949      1949\n",
       "3   ACW00011604   17.1167   -61.7833    SNOW       1949      1949\n",
       "4   ACW00011604   17.1167   -61.7833    SNWD       1949      1949\n",
       "5   ACW00011604   17.1167   -61.7833    PGTM       1949      1949\n",
       "6   ACW00011604   17.1167   -61.7833    WDFG       1949      1949\n",
       "7   ACW00011604   17.1167   -61.7833    WSFG       1949      1949\n",
       "8   ACW00011604   17.1167   -61.7833    WT03       1949      1949\n",
       "9   ACW00011604   17.1167   -61.7833    WT08       1949      1949\n",
       "10  ACW00011604   17.1167   -61.7833    WT16       1949      1949\n",
       "11  ACW00011647   17.1333   -61.7833    TMAX       1961      1961\n",
       "12  ACW00011647   17.1333   -61.7833    TMIN       1961      1961\n",
       "13  ACW00011647   17.1333   -61.7833    PRCP       1957      1970\n",
       "14  ACW00011647   17.1333   -61.7833    SNOW       1957      1970\n",
       "15  ACW00011647   17.1333   -61.7833    SNWD       1957      1970\n",
       "16  ACW00011647   17.1333   -61.7833    WT03       1961      1961\n",
       "17  ACW00011647   17.1333   -61.7833    WT16       1961      1966\n",
       "18  AE000041196   25.3330    55.5170    TMAX       1944      2024\n",
       "19  AE000041196   25.3330    55.5170    TMIN       1944      2024"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load ghcnd-inventory.txt into spark\n",
    "raw_inventory = spark.read.text(inventory_file_path)\n",
    "raw_inventory.show(truncate=False)\n",
    "\n",
    "#parsing using substring pyspark.sql function\n",
    "df_inventory = raw_inventory.select(\n",
    "    substring(\"value\", 1, 11).alias(\"ID\"),\n",
    "    substring(\"value\", 13, 8).cast(DoubleType()).alias(\"LATITUDE\"),\n",
    "    substring(\"value\", 22, 9).cast(DoubleType()).alias(\"LONGITUDE\"),\n",
    "    substring(\"value\", 32, 4).alias(\"ELEMENT\"),\n",
    "    substring(\"value\", 37, 4).cast(IntegerType()).alias(\"FIRSTYEAR\"),\n",
    "    substring(\"value\", 42, 4).cast(IntegerType()).alias(\"LASTYEAR\"),\n",
    ")\n",
    "\n",
    "df_inventory.cache()\n",
    "\n",
    "show_as_html(df_inventory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Analysis\"></a>\n",
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of stations: 127994\n"
     ]
    }
   ],
   "source": [
    "#Q1.a\n",
    "# Count the total number of unique stations\n",
    "# Total stations and active stations\n",
    "\n",
    "total_stations = df_stations.select(\"ID\").distinct().count()\n",
    "print(f\"Total number of stations: {total_stations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stations active in 2024: 36516\n"
     ]
    }
   ],
   "source": [
    "# Active stations *2024\n",
    "df_active_2024 = df_inventory.filter(F.col(\"LASTYEAR\") == 2024)\n",
    "\n",
    "# total distinct stations that were active *2024\n",
    "active_stations_2024 = df_active_2024.select(\"ID\").distinct().count()\n",
    "\n",
    "# Print the number of stations active *2024\n",
    "print(f\"Number of stations active in 2024: {active_stations_2024}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+---------+-------+---------+--------+--------+---------+---------+-----+--------------------+--------+------------+------+\n",
      "|         ID|LATITUDE|LONGITUDE|ELEMENT|FIRSTYEAR|LASTYEAR|LATITUDE|LONGITUDE|ELEVATION|STATE|                NAME|GSN_FLAG|HCN_CRN_FLAG|WMO_ID|\n",
      "+-----------+--------+---------+-------+---------+--------+--------+---------+---------+-----+--------------------+--------+------------+------+\n",
      "|AE000041196|  25.333|   55.517|   TMAX|     1944|    2024|  25.333|   55.517|     34.0|     |SHARJAH INTER. AI...|     GSN|            | 41196|\n",
      "|AE000041196|  25.333|   55.517|   TMIN|     1944|    2024|  25.333|   55.517|     34.0|     |SHARJAH INTER. AI...|     GSN|            | 41196|\n",
      "|AE000041196|  25.333|   55.517|   PRCP|     1944|    2024|  25.333|   55.517|     34.0|     |SHARJAH INTER. AI...|     GSN|            | 41196|\n",
      "|AE000041196|  25.333|   55.517|   TAVG|     1944|    2024|  25.333|   55.517|     34.0|     |SHARJAH INTER. AI...|     GSN|            | 41196|\n",
      "|AEM00041194|  25.255|   55.364|   TMAX|     1983|    2024|  25.255|   55.364|     10.4|     |DUBAI INTL       ...|        |            | 41194|\n",
      "|AEM00041194|  25.255|   55.364|   TMIN|     1983|    2024|  25.255|   55.364|     10.4|     |DUBAI INTL       ...|        |            | 41194|\n",
      "|AEM00041194|  25.255|   55.364|   PRCP|     1983|    2024|  25.255|   55.364|     10.4|     |DUBAI INTL       ...|        |            | 41194|\n",
      "|AEM00041194|  25.255|   55.364|   TAVG|     1983|    2024|  25.255|   55.364|     10.4|     |DUBAI INTL       ...|        |            | 41194|\n",
      "|AEM00041217|  24.433|   54.651|   TMAX|     1983|    2024|  24.433|   54.651|     26.8|     |ABU DHABI INTL   ...|        |            | 41217|\n",
      "|AEM00041217|  24.433|   54.651|   TMIN|     1983|    2024|  24.433|   54.651|     26.8|     |ABU DHABI INTL   ...|        |            | 41217|\n",
      "|AEM00041217|  24.433|   54.651|   PRCP|     1984|    2024|  24.433|   54.651|     26.8|     |ABU DHABI INTL   ...|        |            | 41217|\n",
      "|AEM00041217|  24.433|   54.651|   TAVG|     1983|    2024|  24.433|   54.651|     26.8|     |ABU DHABI INTL   ...|        |            | 41217|\n",
      "|AEM00041218|  24.262|   55.609|   TMAX|     1994|    2024|  24.262|   55.609|    264.9|     |AL AIN INTL      ...|        |            | 41218|\n",
      "|AEM00041218|  24.262|   55.609|   TMIN|     1994|    2024|  24.262|   55.609|    264.9|     |AL AIN INTL      ...|        |            | 41218|\n",
      "|AEM00041218|  24.262|   55.609|   PRCP|     1994|    2024|  24.262|   55.609|    264.9|     |AL AIN INTL      ...|        |            | 41218|\n",
      "|AEM00041218|  24.262|   55.609|   TAVG|     1994|    2024|  24.262|   55.609|    264.9|     |AL AIN INTL      ...|        |            | 41218|\n",
      "|AG000060390| 36.7167|     3.25|   TMAX|     1940|    2024| 36.7167|     3.25|     24.0|     |ALGER-DAR EL BEID...|     GSN|            | 60390|\n",
      "|AG000060390| 36.7167|     3.25|   TMIN|     1940|    2024| 36.7167|     3.25|     24.0|     |ALGER-DAR EL BEID...|     GSN|            | 60390|\n",
      "|AG000060390| 36.7167|     3.25|   PRCP|     1940|    2024| 36.7167|     3.25|     24.0|     |ALGER-DAR EL BEID...|     GSN|            | 60390|\n",
      "|AG000060390| 36.7167|     3.25|   TAVG|     1943|    2024| 36.7167|     3.25|     24.0|     |ALGER-DAR EL BEID...|     GSN|            | 60390|\n",
      "+-----------+--------+---------+-------+---------+--------+--------+---------+---------+-----+--------------------+--------+------------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Number of stations active in 2024: 36516\n"
     ]
    }
   ],
   "source": [
    "# Displaying active stations details by broadcast join between inventory and stations table\n",
    "df_joined = df_inventory.join(F.broadcast(df_stations), on=\"ID\", how=\"inner\")\n",
    "\n",
    "# Filter for stations that were active *2024 LASTYEAR\n",
    "df_active_2024 = df_joined.filter(F.col(\"LASTYEAR\") == 2024)\n",
    "\n",
    "# Get the distinct station IDs to count the unique stations\n",
    "active_station_count = df_active_2024.select(\"ID\").distinct().count()\n",
    "df_active_2024.show()\n",
    "\n",
    "print(f\"Number of stations active in 2024: {active_station_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|HCN_CRN_FLAG|\n",
      "+------------+\n",
      "|            |\n",
      "|         CRN|\n",
      "|         HCN|\n",
      "+------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stations in GCOS surface network \n",
    "#Checking different categories of GCOS surface network\n",
    "df_stations.select(\"HCN_CRN_FLAG\").distinct().show()\n",
    "df_stations.count() == df_stations.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stations in the US Historical Climatology Network (HCN): 1218\n",
      "Number of stations in the US Climate Reference Network (CRN): 234\n",
      "Number of stations that are NOT in HCN or CRN: 126542\n",
      "Number of stations that are in both HCN or CRN: 0\n"
     ]
    }
   ],
   "source": [
    "# Checking HCN and CRN count \n",
    "\n",
    "# Stations in HCN\n",
    "hcn_count = df_stations.filter(F.col(\"HCN_CRN_FLAG\") == \"HCN\").count()\n",
    "\n",
    "# Stations in CRN\n",
    "crn_count = df_stations.filter(F.col(\"HCN_CRN_FLAG\") == \"CRN\").count()\n",
    "\n",
    "# Filter stations that are NOT in HCN or CRN\n",
    "not_hcn_crn_count = df_stations.filter((F.col(\"HCN_CRN_FLAG\") != \"HCN\") & (F.col(\"HCN_CRN_FLAG\") != \"CRN\")).count()\n",
    "\n",
    "# Filter stations that are in both HCN or CRN\n",
    "both_hcn_crn_count = df_stations.filter((F.col(\"HCN_CRN_FLAG\") == \"HCN\") & (F.col(\"HCN_CRN_FLAG\") == \"CRN\")).count()\n",
    "\n",
    "print(f\"Number of stations in the US Historical Climatology Network (HCN): {hcn_count}\")\n",
    "print(f\"Number of stations in the US Climate Reference Network (CRN): {crn_count}\")\n",
    "print(f\"Number of stations that are NOT in HCN or CRN: {not_hcn_crn_count}\")\n",
    "print(f\"Number of stations that are in both HCN or CRN: {both_hcn_crn_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|GSN_FLAG|\n",
      "+--------+\n",
      "|        |\n",
      "|     GSN|\n",
      "+--------+\n",
      "\n",
      "Number of stations in GCOS surface network: 991\n"
     ]
    }
   ],
   "source": [
    "# GCOS surface network count \n",
    "df_stations.select(\"GSN_FLAG\").distinct().show()\n",
    "gsn_count = df_stations.filter(F.col(\"GSN_FLAG\") == \"GSN\").count()\n",
    "print(f\"Number of stations in GCOS surface network: {gsn_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+---------+---------+-----+--------------------+--------+------------+------+\n",
      "|         ID|LATITUDE|LONGITUDE|ELEVATION|STATE|                NAME|GSN_FLAG|HCN_CRN_FLAG|WMO_ID|\n",
      "+-----------+--------+---------+---------+-----+--------------------+--------+------------+------+\n",
      "|USW00003870| 34.8833| -82.2197|    325.8|   SC|GREER            ...|     GSN|         HCN| 72312|\n",
      "|USW00012836| 24.5569| -81.7553|      0.3|   FL|KEY W INTL AP    ...|     GSN|         HCN| 72201|\n",
      "|USW00012921| 29.5442| -98.4839|    243.5|   TX|SAN ANTONIO INTL ...|     GSN|         HCN| 72253|\n",
      "|USW00013782|  32.775| -79.9239|      3.0|   SC|DWTN CHARLESTON  ...|     GSN|         HCN| 72208|\n",
      "|USW00014742| 44.4683|   -73.15|    101.2|   VT|BURLINGTON INTL A...|     GSN|         HCN| 72617|\n",
      "|USW00014771| 43.1111| -76.1039|    125.0|   NY|SYRACUSE HANCOCK ...|     GSN|         HCN| 72519|\n",
      "|USW00014922| 44.8853| -93.2314|    254.5|   MN|MINNEAPOLIS-ST PA...|     GSN|         HCN| 72658|\n",
      "|USW00023044| 31.8122|-106.3775|   1202.1|   TX|EL PASO INTL AP  ...|     GSN|         HCN| 72270|\n",
      "|USW00023051| 36.4483|-103.1536|   1514.6|   NM|CLAYTON MUNI AIR ...|     GSN|         HCN| 72360|\n",
      "|USW00024128| 40.9017|-117.8081|   1310.6|   NV|WINNEMUCCA AP    ...|     GSN|         HCN| 72583|\n",
      "|USW00024144| 46.6044|-111.9892|   1178.1|   MT|HELENA AP ASOS   ...|     GSN|         HCN| 72772|\n",
      "|USW00024213| 40.8097|-124.1603|      6.1|   CA|EUREKA WFO WOODLE...|     GSN|         HCN| 72594|\n",
      "|USW00093193|   36.78|-119.7203|    101.8|   CA|FRESNO YOSEMITE I...|     GSN|         HCN| 72389|\n",
      "|USW00093729| 35.2325| -75.6222|      3.7|   NC|CAPE HATTERAS - B...|     GSN|         HCN| 72304|\n",
      "|USW00094008| 48.2064|-106.6247|    726.6|   MT|GLASGOW          ...|     GSN|         HCN| 72768|\n",
      "+-----------+--------+---------+---------+-----+--------------------+--------+------------+------+\n",
      "\n",
      "Count of statiosn which are in more than one network are: 15\n"
     ]
    }
   ],
   "source": [
    "# stations in more than one network\n",
    "more_than_one_network = df_stations.filter(\n",
    "    (F.col(\"GSN_FLAG\") == \"GSN\") & ((F.col(\"HCN_CRN_FLAG\") == \"HCN\") | (F.col(\"HCN_CRN_FLAG\") == \"CRN\")))\n",
    "more_than_one_network.show()\n",
    "\n",
    "print(f\"Count of statiosn which are in more than one network are: {more_than_one_network.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stations in the Southern Hemisphere: 25357\n"
     ]
    }
   ],
   "source": [
    "# Q1.b\n",
    "# Southern Hemisphere Latitude is less than zero\n",
    "# Stations in Southern Hemisphere\n",
    "# Stations where LATITUDE is less than 0 (Southern Hemisphere)\n",
    "southern_hemisphere_stations = df_stations.filter(F.col(\"LATITUDE\") < 0)\n",
    "\n",
    "# Show the result\n",
    "print(f\"Number of stations in the Southern Hemisphere: {southern_hemisphere_stations.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------------------------------------+\n",
      "|CODE|NAME                                               |\n",
      "+----+---------------------------------------------------+\n",
      "|AQ  |American Samoa [United States]                     |\n",
      "|BD  |Bermuda [United Kingdom]                           |\n",
      "|CJ  |Cayman Islands [United Kingdom]                    |\n",
      "|CK  |Cocos (Keeling) Islands [Australia]                |\n",
      "|CQ  |Northern Mariana Islands [United States]           |\n",
      "|CW  |Cook Islands [New Zealand]                         |\n",
      "|EU  |Europa Island [France]                             |\n",
      "|FG  |French Guiana [France]                             |\n",
      "|FK  |Falkland Islands (Islas Malvinas) [United Kingdom] |\n",
      "|FS  |French Southern and Antarctic Lands [France]       |\n",
      "|GI  |Gibraltar [United Kingdom]                         |\n",
      "|GL  |Greenland [Denmark]                                |\n",
      "|GP  |Guadeloupe [France]                                |\n",
      "|GQ  |Guam [United States]                               |\n",
      "|IO  |British Indian Ocean Territory [United Kingdom]    |\n",
      "|JN  |Jan Mayen [Norway]                                 |\n",
      "|JQ  |Johnston Atoll [United States]                     |\n",
      "|JU  |Juan De Nova Island [France]                       |\n",
      "|KT  |Christmas Island [Australia]                       |\n",
      "|LQ  |Palmyra Atoll [United States]                      |\n",
      "+----+---------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Number of territories: 38\n"
     ]
    }
   ],
   "source": [
    "# Identifying Territories from Countries \n",
    "# Filter rows where the 'NAME' column contains'[' and ']'\n",
    "territories_df = df_countries.filter(F.col(\"NAME\").contains('['))\n",
    "\n",
    "# Show the resulting territories\n",
    "territories_df.show(truncate=False)\n",
    "\n",
    "# Count the number of territories\n",
    "territories_count = territories_df.count()\n",
    "\n",
    "print(f\"Number of territories: {territories_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------------------------------+\n",
      "|CODE|NAME                                     |\n",
      "+----+-----------------------------------------+\n",
      "|AQ  |American Samoa [United States]           |\n",
      "|CQ  |Northern Mariana Islands [United States] |\n",
      "|GQ  |Guam [United States]                     |\n",
      "|JQ  |Johnston Atoll [United States]           |\n",
      "|LQ  |Palmyra Atoll [United States]            |\n",
      "|RQ  |Puerto Rico [United States]              |\n",
      "|VQ  |Virgin Islands [United States]           |\n",
      "|WQ  |Wake Island [United States]              |\n",
      "+----+-----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Identifying United States Territories\n",
    "united_states_territories = df_countries.filter(F.col(\"NAME\").contains('[United States]'))\n",
    "united_states_territories.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stations in U.S. territories (excluding the U.S. itself): 0\n"
     ]
    }
   ],
   "source": [
    "#Broadcast join to check stations are there in total in the territories of the United States around the world\n",
    "#Broadcast the united_states_territories DataFrame\n",
    "broadcast_territories = F.broadcast(united_states_territories)\n",
    "\n",
    "# broadcast join\n",
    "stations_in_us_territories = df_stations.join(\n",
    "    broadcast_territories,\n",
    "    df_stations[\"STATE\"] == broadcast_territories[\"CODE\"],\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Count the number of stations in the U.S. territories\n",
    "stations_in_us_territories_count = stations_in_us_territories.count()\n",
    "\n",
    "\n",
    "print(f\"Number of stations in U.S. territories (excluding the U.S. itself): {stations_in_us_territories_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|STATE|\n",
      "+-----+\n",
      "|   NT|\n",
      "|   NH|\n",
      "|   ND|\n",
      "|   MB|\n",
      "|   AZ|\n",
      "|   NM|\n",
      "|     |\n",
      "|   AR|\n",
      "|   VI|\n",
      "|   KS|\n",
      "|   LA|\n",
      "|   NL|\n",
      "|   NY|\n",
      "|   BC|\n",
      "|   PR|\n",
      "|   WA|\n",
      "|   UT|\n",
      "|   AK|\n",
      "|   YT|\n",
      "|   IA|\n",
      "+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_stations.select(\"STATE\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|COUNTRY_CODE|count|\n",
      "+------------+-----+\n",
      "|TI          |62   |\n",
      "|SW          |1721 |\n",
      "|UG          |8    |\n",
      "|MX          |5249 |\n",
      "|NI          |10   |\n",
      "|GM          |1123 |\n",
      "|TO          |10   |\n",
      "|HU          |10   |\n",
      "|NH          |6    |\n",
      "|MB          |2    |\n",
      "|RS          |1123 |\n",
      "|CJ          |1    |\n",
      "|EG          |23   |\n",
      "|HO          |8    |\n",
      "|IV          |21   |\n",
      "|PS          |12   |\n",
      "|TL          |1    |\n",
      "|AR          |101  |\n",
      "|CG          |13   |\n",
      "|SU          |28   |\n",
      "+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Q1. C Count the total number of stations in each country, and join these counts onto countries so that we can use these counts later if desired.\n",
    "# Stations in each country \n",
    "# Total number of stations in each country\n",
    "\n",
    "# Extract the first two characters from the 'ID' column to get the country code\n",
    "df_stations_with_country_code = df_stations.withColumn(\n",
    "    \"COUNTRY_CODE\", F.expr(\"substring(ID, 1, 2)\")\n",
    ")\n",
    "\n",
    "# Group by the country code and count the number of stations in each country\n",
    "station_counts_by_country = df_stations_with_country_code.groupBy(\"COUNTRY_CODE\").count()\n",
    "station_counts_by_country.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------------------+-----+\n",
      "|CODE|NAME                            |count|\n",
      "+----+--------------------------------+-----+\n",
      "|TI  |Tajikistan                      |62   |\n",
      "|MX  |Mexico                          |5249 |\n",
      "|NI  |Nigeria                         |10   |\n",
      "|SW  |Sweden                          |1721 |\n",
      "|UG  |Uganda                          |8    |\n",
      "|GM  |Germany                         |1123 |\n",
      "|HU  |Hungary                         |10   |\n",
      "|NH  |Vanuatu                         |6    |\n",
      "|TO  |Togo                            |10   |\n",
      "|MB  |Martinique [France]             |2    |\n",
      "|RS  |Russia                          |1123 |\n",
      "|CJ  |Cayman Islands [United Kingdom] |1    |\n",
      "|EG  |Egypt                           |23   |\n",
      "|HO  |Honduras                        |8    |\n",
      "|IV  |Cote D'Ivoire                   |21   |\n",
      "|PS  |Palau                           |12   |\n",
      "|AR  |Argentina                       |101  |\n",
      "|CG  |Congo (Kinshasa)                |13   |\n",
      "|TL  |Tokelau [New Zealand]           |1    |\n",
      "|MF  |Mayotte [France]                |1    |\n",
      "+----+--------------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join total number of stations in each country with countries dataframe\n",
    "# Join the counts onto the df_countries DataFrame\n",
    "countries_with_stations_count = df_countries.join(\n",
    "    station_counts_by_country,\n",
    "    df_countries[\"CODE\"] == station_counts_by_country[\"COUNTRY_CODE\"],\n",
    "    \"left\"\n",
    ").drop(\"COUNTRY_CODE\")\n",
    "\n",
    "countries_with_stations_count.show(truncate=False)\n",
    "\n",
    "# Cross check with sample\n",
    "df_stations.filter(F.col(\"ID\").startswith(\"AY\")).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving modified countries to hdfs output directory\n",
    "parquet_path = \"/user/dca129/assignment1/output/countries/\"\n",
    "\n",
    "countries_with_stations_count.write.mode(\"overwrite\").parquet(parquet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+\n",
      "|STATE|StationCount|\n",
      "+-----+------------+\n",
      "|NT   |137         |\n",
      "|NH   |482         |\n",
      "|ND   |580         |\n",
      "|MB   |734         |\n",
      "|AZ   |1676        |\n",
      "|NM   |2273        |\n",
      "|AR   |952         |\n",
      "|VI   |74          |\n",
      "|NL   |335         |\n",
      "|KS   |2312        |\n",
      "|LA   |836         |\n",
      "|NY   |1872        |\n",
      "|BC   |1714        |\n",
      "|PR   |253         |\n",
      "|WA   |1679        |\n",
      "|UT   |982         |\n",
      "|AK   |1046        |\n",
      "|YT   |128         |\n",
      "|IA   |1070        |\n",
      "|GU   |29          |\n",
      "+-----+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Modifying states to join number of counts of stations\n",
    "# Join df_stations with df_states on STATE and CODE\n",
    "# Count total number of stations in each state\n",
    "df_joined = df_stations.join(\n",
    "    df_states,\n",
    "    df_stations[\"STATE\"] == df_states[\"CODE\"],\n",
    "    \"inner\"\n",
    ")\n",
    "#df_joined.show()\n",
    "# Group by the state and count the number of stations in each state\n",
    "station_counts_by_state = df_joined.groupBy(F.col(\"STATE\")).count()\n",
    "\n",
    "# Rename the count column\n",
    "station_counts_by_state = station_counts_by_state.withColumnRenamed(\"count\", \"StationCount\")\n",
    "\n",
    "station_counts_by_state.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------------+-----+------------+\n",
      "|CODE|NAME                     |STATE|StationCount|\n",
      "+----+-------------------------+-----+------------+\n",
      "|NT  |NORTHWEST TERRITORIES    |NT   |137         |\n",
      "|ND  |NORTH DAKOTA             |ND   |580         |\n",
      "|NH  |NEW HAMPSHIRE            |NH   |482         |\n",
      "|AZ  |ARIZONA                  |AZ   |1676        |\n",
      "|MB  |MANITOBA                 |MB   |734         |\n",
      "|NM  |NEW MEXICO               |NM   |2273        |\n",
      "|AR  |ARKANSAS                 |AR   |952         |\n",
      "|VI  |VIRGIN ISLANDS           |VI   |74          |\n",
      "|KS  |KANSAS                   |KS   |2312        |\n",
      "|LA  |LOUISIANA                |LA   |836         |\n",
      "|NL  |NEWFOUNDLAND AND LABRADOR|NL   |335         |\n",
      "|BC  |BRITISH COLUMBIA         |BC   |1714        |\n",
      "|NY  |NEW YORK                 |NY   |1872        |\n",
      "|PR  |PUERTO RICO              |PR   |253         |\n",
      "|AK  |ALASKA                   |AK   |1046        |\n",
      "|UT  |UTAH                     |UT   |982         |\n",
      "|WA  |WASHINGTON               |WA   |1679        |\n",
      "|IA  |IOWA                     |IA   |1070        |\n",
      "|YT  |YUKON TERRITORY          |YT   |128         |\n",
      "|GU  |GUAM                     |GU   |29          |\n",
      "+----+-------------------------+-----+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2193"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join total number of stations in each state\n",
    "# Join the counts onto the df_countries DataFrame\n",
    "states_with_stations_count = df_states.join(\n",
    "    station_counts_by_state,\n",
    "    df_states[\"CODE\"] == station_counts_by_state[\"STATE\"],\n",
    "    \"left\"\n",
    ")\n",
    "#.drop(\"COUNTRY_CODE)\n",
    "states_with_stations_count.show(truncate=False)\n",
    "\n",
    "# Cross check with one sample \n",
    "df_stations.filter(F.col(\"STATE\")==\"IL\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the output\n",
    "parquet_path = \"/user/dca129/assignment1/output/states/\"\n",
    "\n",
    "states_with_stations_count.write.mode(\"overwrite\").parquet(parquet_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2.a. function that computes the geographical distance between two stations using their latitude and longitude as arguments.\n",
    "# Geographical Distance between two stations\n",
    "\n",
    "#Haversine formula to calculate the distance between two lat-long coordinates\n",
    "def haversine_distance_calculator(lat1, lon1, lat2, lon2):\n",
    "    R = 6371.0  # Radius of Earth in kilometers\n",
    "\n",
    "    lat1 = math.radians(lat1)\n",
    "    lon1 = math.radians(lon1)\n",
    "    lat2 = math.radians(lat2)\n",
    "    lon2 = math.radians(lon2)\n",
    "\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "\n",
    "    distance = R * c\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the Haversine function as a UDF\n",
    "haversine_udf = F.udf(haversine_distance_calculator, DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+---------+---------+-----+--------------------+--------+------------+------+\n",
      "|         ID|LATITUDE|LONGITUDE|ELEVATION|STATE|                NAME|GSN_FLAG|HCN_CRN_FLAG|WMO_ID|\n",
      "+-----------+--------+---------+---------+-----+--------------------+--------+------------+------+\n",
      "|ACW00011604| 17.1167| -61.7833|     10.1|     |ST JOHNS COOLIDGE...|        |            |      |\n",
      "|ACW00011647| 17.1333| -61.7833|     19.2|     |ST JOHNS         ...|        |            |      |\n",
      "+-----------+--------+---------+---------+-----+--------------------+--------+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Selecting small subset of stations\n",
    "df_stations_subset = df_stations.limit(2)\n",
    "df_stations_subset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross join on subset of stations\n",
    "# Perform CROSS JOIN on the small subset of stations\n",
    "df_crossed_subset = df_stations_subset.alias('df1').crossJoin(df_stations_subset.alias('df2')) \\\n",
    "    .select(\n",
    "        F.col('df1.ID').alias('ID1'),\n",
    "        F.col('df1.LATITUDE').alias('LAT1'),\n",
    "        F.col('df1.LONGITUDE').alias('LON1'),\n",
    "        F.col('df2.ID').alias('ID2'),\n",
    "        F.col('df2.LATITUDE').alias('LAT2'),\n",
    "        F.col('df2.LONGITUDE').alias('LON2')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+---------+-----------+-------+--------+------------------+\n",
      "|ID1        |LAT1   |LON1     |ID2        |LAT2   |LON2    |Distance KM       |\n",
      "+-----------+-------+---------+-----------+-------+--------+------------------+\n",
      "|US1WAKG0076|47.3308|-122.2673|ACW00011604|17.1167|-61.7833|6407.0777760856   |\n",
      "|US1WAKG0076|47.3308|-122.2673|ACW00011647|17.1333|-61.7833|6405.75676345013  |\n",
      "|US1WAKG0077|47.5755|-122.2134|ACW00011604|17.1167|-61.7833|6407.861135721299 |\n",
      "|US1WAKG0077|47.5755|-122.2134|ACW00011647|17.1333|-61.7833|6406.5335512881675|\n",
      "+-----------+-------+---------+-----------+-------+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply the Haversine UDF to calculate distances\n",
    "# Apply the UDF to calculate the distance between station pairs\n",
    "df_with_distances_subset = df_crossed_subset.withColumn(\n",
    "    'Distance KM',\n",
    "    haversine_udf(F.col('LAT1'), F.col('LON1'), F.col('LAT2'), F.col('LON2'))\n",
    ")\n",
    "\n",
    "df_with_distances_subset.show(truncate=False)\n",
    "\n",
    "# https://latlongdata.com/distance-calculator/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+---------+---------+-----+--------------------+--------+------------+------+\n",
      "|         ID|LATITUDE|LONGITUDE|ELEVATION|STATE|                NAME|GSN_FLAG|HCN_CRN_FLAG|WMO_ID|\n",
      "+-----------+--------+---------+---------+-----+--------------------+--------+------------+------+\n",
      "|NZ000093012|   -35.1|  173.267|     54.0|     |KAITAIA          ...|        |            | 93119|\n",
      "|NZ000093292|  -38.65|  177.983|      5.0|     |GISBORNE AERODROM...|     GSN|            | 93292|\n",
      "|NZ000093417|   -40.9|  174.983|      7.0|     |PARAPARAUMU AWS  ...|     GSN|            | 93420|\n",
      "|NZ000093844| -46.417|  168.333|      2.0|     |INVERCARGILL AIRP...|     GSN|            | 93845|\n",
      "|NZ000933090| -39.017|  174.183|     32.0|     |NEW PLYMOUTH AWS ...|     GSN|            | 93309|\n",
      "|NZ000936150| -42.717|  170.983|     40.0|     |HOKITIKA AERODROM...|        |            | 93781|\n",
      "|NZ000937470| -44.517|    169.9|    488.0|     |TARA HILLS       ...|     GSN|            | 93747|\n",
      "|NZM00093110|   -37.0|    174.8|      7.0|     |AUCKLAND AERO AWS...|        |            | 93110|\n",
      "|NZM00093439| -41.333|    174.8|     12.0|     |WELLINGTON AERO A...|        |            | 93439|\n",
      "|NZM00093678| -42.417|    173.7|    101.0|     |KAIKOURA         ...|        |            | 93678|\n",
      "|NZM00093781| -43.489|  172.532|     37.5|     |CHRISTCHURCH INTL...|        |            | 93781|\n",
      "+-----------+--------+---------+---------+-----+--------------------+--------+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q2.b. What two stations are geographically closest together in New Zealand?\n",
    "# New Zealnd range of Latitide and Longitude as follows - Latitude - (-34.5 to -47.5) Longitude - (166.5 to 178.5)\n",
    "df_nz_stations = df_stations.filter(\n",
    "    (F.col(\"LATITUDE\") >= -47.5) & (F.col(\"LATITUDE\") <= -34.5) &\n",
    "    (F.col(\"LONGITUDE\") >= 166.5) & (F.col(\"LONGITUDE\") <= 178.5)\n",
    ")\n",
    "\n",
    "df_nz_stations.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross join on New Zealand stations\n",
    "# Generate pairs of New Zealand stations\n",
    "df_nz_crossed = df_nz_stations.alias('df1').crossJoin(df_nz_stations.alias('df2')) \\\n",
    "    .select(\n",
    "        F.col('df1.ID').alias('ID1'),\n",
    "        F.col('df1.LATITUDE').alias('LAT1'),\n",
    "        F.col('df1.LONGITUDE').alias('LON1'),\n",
    "        F.col('df2.ID').alias('ID2'),\n",
    "        F.col('df2.LATITUDE').alias('LAT2'),\n",
    "        F.col('df2.LONGITUDE').alias('LON2')\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the Haversine UDF to compute the distance between station pairs\n",
    "df_nz_distances = df_nz_crossed.withColumn(\n",
    "    'Distance KM',\n",
    "    haversine_udf(F.col('LAT1'), F.col('LON1'), F.col('LAT2'), F.col('LON2'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+-------+-----------+-------+-----+-----------------+\n",
      "|ID1        |LAT1 |LON1   |ID2        |LAT2   |LON2 |Distance KM      |\n",
      "+-----------+-----+-------+-----------+-------+-----+-----------------+\n",
      "|NZ000093417|-40.9|174.983|NZM00093439|-41.333|174.8|50.52902648213863|\n",
      "+-----------+-----+-------+-----------+-------+-----+-----------------+\n",
      "\n",
      "+-----------+-----------+\n",
      "|        ID1|        ID2|\n",
      "+-----------+-----------+\n",
      "|NZ000093417|NZM00093439|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finding Closest pair of stations\n",
    "# Filter out rows where ID1 and ID2 are the same (comparing the same station)\n",
    "df_non_same_stations = df_nz_distances.filter(F.col('ID1') != F.col('ID2'))\n",
    "\n",
    "# Find the closest pair of stations by ordering by distance and selecting the minimum\n",
    "df_closest_stations = df_non_same_stations.orderBy(F.col('Distance KM')).limit(1)\n",
    "\n",
    "# Show the closest pair of stations\n",
    "df_closest_stations.show(truncate=False)\n",
    "\n",
    "df_closest_stations.select(F.col(\"ID1\"),F.col(\"ID2\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3119374043"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3.a . # Daily climate summaries\n",
    "# Count number of rows in daily\n",
    "hdfs_daily_path = \"hdfs:///data/ghcnd/daily/\"\n",
    "\n",
    "daily_data = (\n",
    "    spark.read.format(\"com.databricks.spark.csv\")\n",
    "    .option(\"header\",\"false\")\n",
    "    .option(\"inferSchema\", \"false\")\n",
    "    .schema(daily_schema)\n",
    "    .load(hdfs_daily_path)\n",
    ")\n",
    "\n",
    "daily_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|Element|Observation_Count|\n",
      "+-------+-----------------+\n",
      "|   PRCP|       1073530896|\n",
      "|   TMAX|        457927581|\n",
      "|   TMIN|        456739567|\n",
      "|   SNOW|        356187192|\n",
      "|   SNWD|        299076145|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q3.b. \n",
    "# Observations in daily involving core elements\n",
    "# The five core elements:\n",
    "#PRCP = Precipitation (tenths of mm)\n",
    "#SNOW = Snowfall (mm)\n",
    "#SNWD = Snow depth (mm)\n",
    "#TMAX = Maximum temperature (tenths of degrees C)\n",
    "#TMIN = Minimum temperature (tenths of degrees C)\n",
    "\n",
    "# Define the five core elements\n",
    "core_elements = ['TMAX', 'TMIN', 'PRCP', 'SNOW', 'SNWD']\n",
    "\n",
    "# Filter the data for the five core elements\n",
    "filtered_data = daily_data.filter(F.col(\"Element\").isin(core_elements))\n",
    "\n",
    "# Count the number of observations for each core element\n",
    "element_counts = (\n",
    "    filtered_data.groupBy(\"Element\")\n",
    "    .agg(F.count(\"*\").alias(\"Observation_Count\"))\n",
    "    .orderBy(F.desc(\"Observation_Count\"))\n",
    ")\n",
    "\n",
    "element_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|Element|Observation_Count|\n",
      "+-------+-----------------+\n",
      "|   PRCP|       1073530896|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the element with the most observations\n",
    "most_observed_element = element_counts.limit(1)\n",
    "most_observed_element.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3.c\n",
    "# Filter daily_data for TMAX and TMIN observations\n",
    "# Counting observations of TMAX which do not have corresponding TMIN\n",
    "tmax_data = daily_data.filter(F.col(\"Element\") == \"TMAX\")\n",
    "tmin_data = daily_data.filter(F.col(\"Element\") == \"TMIN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a left join to find TMAX observations without corresponding TMIN observations\n",
    "# Join on ID (station ID) and Date columns\n",
    "tmax_without_tmin = tmax_data.join(\n",
    "    tmin_data, \n",
    "    on=[\"ID\", \"Date\"], \n",
    "    how=\"left_anti\"  # This gives us TMAX rows that do not have matching TMIN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total TMAX observations without corresponding TMIN: 10567304\n"
     ]
    }
   ],
   "source": [
    "# Count the total number of TMAX observations without a corresponding TMIN\n",
    "#tmax_without_tmin_count = tmax_without_tmin.count()\n",
    "print(f\"Total TMAX observations without corresponding TMIN: {tmax_without_tmin.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique stations contributing to these observations: 28716\n"
     ]
    }
   ],
   "source": [
    "# Count the number of unique stations that contributed to these observations\n",
    "#unique_stations_count = tmax_without_tmin.select(\"ID\").distinct().count()\n",
    "print(f\"Number of unique stations contributing to these observations: {tmax_without_tmin.select('ID').distinct().count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><b>Spark</b></p><p>The spark session is <b><span style=\"color:red\">stopped</span></b>, confirm that <code>ojo35 (jupyter)</code> is under the completed applications section in the Spark UI.</p><ul><li><a href=\"http://mathmadslinux2p.canterbury.ac.nz:8080/\" target=\"_blank\">Spark UI</a></li></ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell before closing the notebook or kill your spark application by hand using the link in the Spark UI\n",
    "\n",
    "stop_spark()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
